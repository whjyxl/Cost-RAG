# Dockerå®¹å™¨åŒ–é…ç½®

## ğŸ“‹ ç›®å½•

- [Dockeræ¦‚è¿°](#dockeræ¦‚è¿°)
- [å¤šå®¹å™¨æ¶æ„](#å¤šå®¹å™¨æ¶æ„)
- [Docker Composeé…ç½®](#docker-composeé…ç½®)
- [æœåŠ¡é…ç½®è¯¦è§£](#æœåŠ¡é…ç½®è¯¦è§£)
- [ç½‘ç»œä¸å­˜å‚¨](#ç½‘ç»œä¸å­˜å‚¨)
- [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
- [éƒ¨ç½²æµç¨‹](#éƒ¨ç½²æµç¨‹)
- [ç›‘æ§ä¸æ—¥å¿—](#ç›‘æ§ä¸æ—¥å¿—)
- [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

## ğŸ³ Dockeræ¦‚è¿°

Cost-RAGç³»ç»Ÿé‡‡ç”¨å¾®æœåŠ¡æ¶æ„ï¼Œé€šè¿‡Dockerå®¹å™¨åŒ–å®ç°æœåŠ¡çš„ç‹¬ç«‹éƒ¨ç½²ã€æ‰©å±•å’Œç®¡ç†ã€‚æ¯ä¸ªæœåŠ¡è¿è¡Œåœ¨ç‹¬ç«‹çš„å®¹å™¨ä¸­ï¼Œé€šè¿‡Docker Composeè¿›è¡Œç¼–æ’ã€‚

### å®¹å™¨åŒ–ä¼˜åŠ¿

- **ç¯å¢ƒä¸€è‡´æ€§**: å¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ç¯å¢ƒå®Œå…¨ä¸€è‡´
- **å¿«é€Ÿéƒ¨ç½²**: ç§’çº§å¯åŠ¨ï¼Œæ”¯æŒå¼¹æ€§æ‰©ç¼©å®¹
- **èµ„æºéš”ç¦»**: CPUã€å†…å­˜ã€ç½‘ç»œèµ„æºéš”ç¦»
- **ç‰ˆæœ¬ç®¡ç†**: é•œåƒç‰ˆæœ¬åŒ–ï¼Œæ”¯æŒå›æ»š
- **è¿ç»´ç®€åŒ–**: ç»Ÿä¸€çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†

## ğŸ—ï¸ å¤šå®¹å™¨æ¶æ„

### æœåŠ¡å®¹å™¨åˆ’åˆ†

```mermaid
graph TB
    subgraph "Load Balancer"
        LB[Nginx:80]
    end

    subgraph "Application Layer"
        API[FastAPI:8000]
        WS[WebSocket:8001]
        WORKER[Celery Workers:8002]
    end

    subgraph "Data Layer"
        PG[PostgreSQL:5432]
        REDIS[Redis:6379]
        MILVUS[Milvus:19530]
        NEO4J[Neo4j:7474]
        MINIO[MinIO:9000]
    end

    subgraph "External Services"
        RABBIT[RabbitMQ:5672]
        ELASTIC[Elasticsearch:9200]
    end

    LB --> API
    LB --> WS
    API --> PG
    API --> REDIS
    API --> MILVUS
    API --> NEO4J
    API --> MINIO

    WORKER --> RABBIT
    WORKER --> PG
    WORKER --> REDIS
    WORKER --> ELASTIC

    WS --> REDIS
```

## ğŸ“‹ Docker Composeé…ç½®

### ä¸»é…ç½®æ–‡ä»¶ (docker-compose.yml)

```yaml
version: '3.8'

services:
  # APIæœåŠ¡
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: cost-rag-api
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://cost_rag:${POSTGRES_PASSWORD}@postgres:5432/cost_rag
      - REDIS_URL=redis://redis:6379/0
      - MILVUS_HOST=milvus
      - MILVUS_PORT=19530
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
      - JWT_SECRET=${JWT_SECRET}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - CELERY_BROKER_URL=pyamqp://guest:guest@rabbitmq:5672/
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
    volumes:
      - ./logs:/app/logs
      - ./uploads:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      milvus:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # WebSocketæœåŠ¡
  websocket:
    build:
      context: .
      dockerfile: Dockerfile.websocket
    container_name: cost-rag-websocket
    ports:
      - "8001:8001"
    environment:
      - REDIS_URL=redis://redis:6379/0
      - JWT_SECRET=${JWT_SECRET}
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Celery Worker
  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: cost-rag-worker
    environment:
      - DATABASE_URL=postgresql://cost_rag:${POSTGRES_PASSWORD}@postgres:5432/cost_rag
      - REDIS_URL=redis://redis:6379/0
      - MILVUS_HOST=milvus
      - MILVUS_PORT=19530
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - CELERY_BROKER_URL=pyamqp://guest:guest@rabbitmq:5672/
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
    volumes:
      - ./logs:/app/logs
      - ./uploads:/app/uploads
      - ./models:/app/models
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      replicas: 2

  # PostgreSQLæ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    container_name: cost-rag-postgres
    environment:
      - POSTGRES_DB=cost_rag
      - POSTGRES_USER=cost_rag
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    ports:
      - "5432:5432"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U cost_rag -d cost_rag"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: cost-rag-redis
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Milvuså‘é‡æ•°æ®åº“
  milvus:
    image: milvusdb/milvus:v2.3.0
    container_name: cost-rag-milvus
    command: ["milvus", "run", "standalone"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
    volumes:
      - milvus_data:/var/lib/milvus
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      etcd:
        condition: service_healthy
      minio:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

  # etcd for Milvus
  etcd:
    image: quay.io/coreos/etcd:v3.5.5
    container_name: cost-rag-etcd
    command:
      - etcd
      - --advertise-client-urls=http://127.0.0.1:2379
      - --listen-client-urls=http://0.0.0.0:2379
      - --data-dir=/etcd
    volumes:
      - etcd_data:/etcd
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MinIOå¯¹è±¡å­˜å‚¨
  minio:
    image: minio/minio:RELEASE.2023-12-14T18-51-57Z
    container_name: cost-rag-minio
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ACCESS_KEY}
      - MINIO_ROOT_PASSWORD=${MINIO_SECRET_KEY}
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Neo4jå›¾æ•°æ®åº“
  neo4j:
    image: neo4j:5.12-community
    container_name: cost-rag-neo4j
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD}
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*,gds.*
      - NEO4J_dbms_memory_heap_initial__size=512m
      - NEO4J_dbms_memory_heap_max__size=2G
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins
    ports:
      - "7474:7474"
      - "7687:7687"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "${NEO4J_PASSWORD}", "RETURN 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # RabbitMQæ¶ˆæ¯é˜Ÿåˆ—
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: cost-rag-rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=guest
      - RABBITMQ_DEFAULT_PASS=guest
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Elasticsearchæœç´¢å¼•æ“
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.0
    container_name: cost-rag-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Nginxåå‘ä»£ç†
  nginx:
    image: nginx:alpine
    container_name: cost-rag-nginx
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - ./static:/var/www/static
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - api
      - websocket
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_data:
  redis_data:
  milvus_data:
  etcd_data:
  minio_data:
  neo4j_data:
  neo4j_logs:
  neo4j_import:
  neo4j_plugins:
  rabbitmq_data:
  elasticsearch_data:

networks:
  default:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

### å¼€å‘ç¯å¢ƒé…ç½® (docker-compose.dev.yml)

```yaml
version: '3.8'

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile.dev
    volumes:
      - .:/app
      - /app/__pycache__
    environment:
      - DEBUG=true
      - LOG_LEVEL=DEBUG
      - RELOAD=true
    command: uvicorn cost_rag.main:app --host 0.0.0.0 --port 8000 --reload

  worker:
    build:
      context: .
      dockerfile: Dockerfile.dev
    volumes:
      - .:/app
      - /app/__pycache__
    environment:
      - DEBUG=true
      - LOG_LEVEL=DEBUG
    command: celery -A cost_rag.celery worker --loglevel=info --reload

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    volumes:
      - ./frontend:/app
      - /app/node_modules
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
      - REACT_APP_WS_URL=ws://localhost:8001
    command: npm start
```

### ç”Ÿäº§ç¯å¢ƒé…ç½® (docker-compose.prod.yml)

```yaml
version: '3.8'

services:
  api:
    image: cost-rag/api:${VERSION}
    environment:
      - DEBUG=false
      - LOG_LEVEL=INFO
      - WORKERS=4
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  worker:
    image: cost-rag/worker:${VERSION}
    deploy:
      replicas: 5
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=cost_rag_prod
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
      - postgres_backups:/backups

volumes:
  postgres_prod_data:
  postgres_backups:
```

## âš™ï¸ æœåŠ¡é…ç½®è¯¦è§£

### APIæœåŠ¡Dockerfile

```dockerfile
# Dockerfile.api
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    curl \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
COPY requirements-prod.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements-prod.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY cost_rag/ ./cost_rag/
COPY scripts/ ./scripts/

# åˆ›å»ºérootç”¨æˆ·
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["gunicorn", "cost_rag.main:app", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "--bind", "0.0.0.0:8000"]
```

### WorkeræœåŠ¡Dockerfile

```dockerfile
# Dockerfile.worker
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–ï¼ˆåŒ…æ‹¬æ–‡æ¡£å¤„ç†å·¥å…·ï¼‰
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    poppler-utils \
    tesseract-ocr \
    tesseract-ocr-chi-sim \
    libtesseract-dev \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
COPY requirements-prod.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements-prod.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY cost_rag/ ./cost_rag/
COPY scripts/ ./scripts/

# åˆ›å»ºérootç”¨æˆ·
RUN useradd -m -u 1000 worker && chown -R worker:worker /app
USER worker

# å¯åŠ¨Celery Worker
CMD ["celery", "-A", "cost_rag.celery", "worker", "--loglevel=info", "--concurrency=4"]
```

### å¼€å‘ç¯å¢ƒDockerfile

```dockerfile
# Dockerfile.dev
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…å¼€å‘å·¥å…·
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    curl \
    git \
    vim \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
COPY requirements-dev.txt .

# å®‰è£…Pythonä¾èµ–ï¼ˆåŒ…æ‹¬å¼€å‘ä¾èµ–ï¼‰
RUN pip install --no-cache-dir -r requirements-dev.txt

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# é»˜è®¤å‘½ä»¤
CMD ["uvicorn", "cost_rag.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
```

## ğŸŒ ç½‘ç»œä¸å­˜å‚¨

### ç½‘ç»œé…ç½®

```yaml
# docker-compose.networks.yml
version: '3.8'

networks:
  frontend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.1.0/24

  backend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.2.0/24

  database:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.3.0/24
    internal: true

services:
  api:
    networks:
      - frontend
      - backend

  postgres:
    networks:
      - backend
      - database

  redis:
    networks:
      - backend
      - database
```

### å­˜å‚¨é…ç½®

```yaml
# docker-compose.volumes.yml
version: '3.8'

volumes:
  # æ•°æ®åº“æ•°æ®
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/cost-rag/postgres

  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/cost-rag/redis

  # å‘é‡æ•°æ®åº“æ•°æ®
  milvus_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/cost-rag/milvus

  # å¯¹è±¡å­˜å‚¨æ•°æ®
  minio_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/cost-rag/minio

  # å›¾æ•°æ®åº“æ•°æ®
  neo4j_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/cost-rag/neo4j

  # æ—¥å¿—å­˜å‚¨
  logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/cost-rag/logs

  # ä¸Šä¼ æ–‡ä»¶å­˜å‚¨
  uploads:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/cost-rag/uploads
```

## ğŸ”§ ç¯å¢ƒé…ç½®

### ç¯å¢ƒå˜é‡æ–‡ä»¶ (.env)

```bash
# æ•°æ®åº“é…ç½®
POSTGRES_PASSWORD=your_postgres_password
DATABASE_URL=postgresql://cost_rag:${POSTGRES_PASSWORD}@postgres:5432/cost_rag

# Redisé…ç½®
REDIS_URL=redis://redis:6379/0

# Milvusé…ç½®
MILVUS_HOST=milvus
MILVUS_PORT=19530

# Neo4jé…ç½®
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

# MinIOé…ç½®
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=your_minio_access_key
MINIO_SECRET_KEY=your_minio_secret_key
MINIO_BUCKET_NAME=cost-rag-documents

# RabbitMQé…ç½®
RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/

# JWTé…ç½®
JWT_SECRET=your_jwt_secret_key
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# OpenAIé…ç½®
OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=gpt-4-turbo

# åº”ç”¨é…ç½®
DEBUG=false
LOG_LEVEL=INFO
CORS_ORIGINS=["http://localhost:3000", "https://yourdomain.com"]

# æ–‡ä»¶ä¸Šä¼ é…ç½®
MAX_FILE_SIZE=100MB
ALLOWED_EXTENSIONS=pdf,docx,xlsx,ppt,jpg,png

# Celeryé…ç½®
CELERY_BROKER_URL=pyamqp://guest:guest@rabbitmq:5672/
CELERY_RESULT_BACKEND=redis://redis:6379/1

# ç‰ˆæœ¬é…ç½®
VERSION=1.0.0
BUILD_DATE=2024-01-01
```

### ç¯å¢ƒç‰¹å®šé…ç½® (.env.dev)

```bash
# å¼€å‘ç¯å¢ƒé…ç½®
DEBUG=true
LOG_LEVEL=DEBUG
RELOAD=true

# å¼€å‘æ•°æ®åº“
POSTGRES_PASSWORD=dev_password
DATABASE_URL=postgresql://cost_rag:dev_password@postgres:5432/cost_rag_dev

# çƒ­é‡è½½é…ç½®
UVICORN_RELOAD=true
UVICORN_RELOAD_DIRS=/app

# æµ‹è¯•é…ç½®
TESTING=true
MOCK_EXTERNAL_APIS=true
```

### ç”Ÿäº§ç¯å¢ƒé…ç½® (.env.prod)

```bash
# ç”Ÿäº§ç¯å¢ƒé…ç½®
DEBUG=false
LOG_LEVEL=WARNING
RELOAD=false

# ç”Ÿäº§æ•°æ®åº“
POSTGRES_PASSWORD=super_secure_password
DATABASE_URL=postgresql://cost_rag:${POSTGRES_PASSWORD}@postgres:5432/cost_rag_prod

# æ€§èƒ½é…ç½®
WORKERS=4
WORKER_CONNECTIONS=1000
KEEPALIVE=2

# å®‰å…¨é…ç½®
CORS_ORIGINS=["https://yourdomain.com"]
ALLOWED_HOSTS=["api.yourdomain.com"]
```

## ğŸš€ éƒ¨ç½²æµç¨‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
mkdir -p logs uploads data models config

# è®¾ç½®æƒé™
chmod 755 logs uploads data models config

# åˆ›å»ºç¯å¢ƒå˜é‡æ–‡ä»¶
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶ï¼Œå¡«å…¥å®é™…é…ç½®
```

### 2. æ„å»ºé•œåƒ

```bash
# å¼€å‘ç¯å¢ƒ
docker-compose -f docker-compose.yml -f docker-compose.dev.yml build

# ç”Ÿäº§ç¯å¢ƒ
docker-compose -f docker-compose.yml -f docker-compose.prod.yml build

# æˆ–è€…ä»…æ„å»ºç‰¹å®šæœåŠ¡
docker-compose build api
docker-compose build worker
```

### 3. å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# å¯åŠ¨ç‰¹å®šæœåŠ¡
docker-compose up -d postgres redis
docker-compose up -d api worker

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f api
docker-compose logs -f worker
```

### 4. æ•°æ®åº“åˆå§‹åŒ–

```bash
# ç­‰å¾…æ•°æ®åº“æœåŠ¡å°±ç»ª
docker-compose exec postgres pg_isready -U cost_rag

# è¿è¡Œæ•°æ®åº“è¿ç§»
docker-compose exec api alembic upgrade head

# åˆå§‹åŒ–æ•°æ®
docker-compose exec api python scripts/init_data.py
```

### 5. éªŒè¯éƒ¨ç½²

```bash
# æ£€æŸ¥APIå¥åº·çŠ¶æ€
curl http://localhost:8000/health

# æ£€æŸ¥WebSocketè¿æ¥
curl -i -N -H "Connection: Upgrade" \
     -H "Upgrade: websocket" \
     -H "Sec-WebSocket-Key: SGVsbG8sIHdvcmxkIQ==" \
     -H "Sec-WebSocket-Version: 13" \
     http://localhost:8001/ws

# æµ‹è¯•APIç«¯ç‚¹
curl -X POST http://localhost:8000/api/v1/auth/login \
     -H "Content-Type: application/json" \
     -d '{"username": "admin", "password": "password"}'
```

### 6. åœæ­¢ä¸æ¸…ç†

```bash
# åœæ­¢æœåŠ¡
docker-compose down

# åœæ­¢å¹¶åˆ é™¤æ•°æ®å·
docker-compose down -v

# æ¸…ç†æœªä½¿ç”¨çš„é•œåƒ
docker image prune -f

# æ¸…ç†æ‰€æœ‰æœªä½¿ç”¨çš„èµ„æº
docker system prune -a -f
```

## ğŸ“Š ç›‘æ§ä¸æ—¥å¿—

### æ—¥å¿—é…ç½®

```yaml
# docker-compose.logging.yml
version: '3.8'

x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"
    labels: "service,environment"

services:
  api:
    logging: *default-logging
    environment:
      - LOG_LEVEL=INFO
      - LOG_FORMAT=json
    volumes:
      - ./logs:/app/logs

  worker:
    logging: *default-logging
    environment:
      - LOG_LEVEL=INFO
      - LOG_FORMAT=json
    volumes:
      - ./logs:/app/logs

  postgres:
    logging: *default-logging
    environment:
      - POSTGRES_LOG_STATEMENT=all
    volumes:
      - ./logs/postgres:/var/log/postgresql

  nginx:
    logging: *default-logging
    volumes:
      - ./logs/nginx:/var/log/nginx
```

### ç›‘æ§é…ç½®

```yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  # Prometheusç›‘æ§
  prometheus:
    image: prom/prometheus:latest
    container_name: cost-rag-prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'

  # Grafanaå¯è§†åŒ–
  grafana:
    image: grafana/grafana:latest
    container_name: cost-rag-grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    ports:
      - "3001:3000"
    depends_on:
      - prometheus

  # Node Exporter
  node-exporter:
    image: prom/node-exporter:latest
    container_name: cost-rag-node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'

volumes:
  prometheus_data:
  grafana_data:
```

## ğŸ”§ æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜è¯Šæ–­

```bash
# 1. æœåŠ¡å¯åŠ¨å¤±è´¥
docker-compose logs api
docker-compose ps

# 2. æ•°æ®åº“è¿æ¥é—®é¢˜
docker-compose exec postgres pg_isready -U cost_rag
docker-compose exec api python -c "from cost_rag.database import engine; print(engine.execute('SELECT 1').scalar())"

# 3. å†…å­˜ä¸è¶³é—®é¢˜
docker stats
docker-compose exec api free -h

# 4. ç£ç›˜ç©ºé—´é—®é¢˜
docker system df
docker-compose exec api df -h

# 5. ç½‘ç»œè¿æ¥é—®é¢˜
docker-compose exec api ping postgres
docker-compose exec api nslookup postgres
```

### æ€§èƒ½è°ƒä¼˜

```yaml
# docker-compose.performance.yml
version: '3.8'

services:
  api:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    environment:
      - WORKERS=4
      - WORKER_CONNECTIONS=1000
      - MAX_REQUESTS=1000
      - MAX_REQUESTS_JITTER=100
      - PRELOAD_APP=true

  postgres:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    environment:
      - POSTGRES_SHARED_PRELOAD_LIBRARIES=pg_stat_statements
      - POSTGRES_MAX_CONNECTIONS=200
      - POSTGRES_SHARED_BUFFERS=1GB
      - POSTGRES_EFFECTIVE_CACHE_SIZE=3GB
      - POSTGRES_WORK_MEM=16MB
      - POSTGRES_MAINTENANCE_WORK_MEM=256MB

  redis:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    command: redis-server --maxmemory 1gb --maxmemory-policy allkeys-lru
```

### å¤‡ä»½ä¸æ¢å¤

```bash
#!/bin/bash
# backup.sh

# è®¾ç½®å˜é‡
BACKUP_DIR="/backup/cost-rag"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="cost-rag-backup-${DATE}.tar.gz"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p ${BACKUP_DIR}

# å¤‡ä»½æ•°æ®åº“
docker-compose exec -T postgres pg_dump -U cost_rag cost_rag > ${BACKUP_DIR}/postgres_${DATE}.sql

# å¤‡ä»½Redis
docker-compose exec -T redis redis-cli --rdb - > ${BACKUP_DIR}/redis_${DATE}.rdb

# å¤‡ä»½Milvus
docker cp cost-rag-milvus:/var/lib/milvus ${BACKUP_DIR}/milvus_${DATE}

# å¤‡ä»½MinIO
docker cp cost-rag-minio:/data ${BACKUP_DIR}/minio_${DATE}

# å¤‡ä»½Neo4j
docker cp cost-rag-neo4j:/data ${BACKUP_DIR}/neo4j_${DATE}

# æ‰“åŒ…å¤‡ä»½æ–‡ä»¶
tar -czf ${BACKUP_DIR}/${BACKUP_FILE} -C ${BACKUP_DIR} \
    postgres_${DATE}.sql \
    redis_${DATE}.rdb \
    milvus_${DATE} \
    minio_${DATE} \
    neo4j_${DATE}

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm -rf ${BACKUP_DIR}/postgres_${DATE}.sql
rm -rf ${BACKUP_DIR}/redis_${DATE}.rdb
rm -rf ${BACKUP_DIR}/milvus_${DATE}
rm -rf ${BACKUP_DIR}/minio_${DATE}
rm -rf ${BACKUP_DIR}/neo4j_${DATE}

echo "Backup completed: ${BACKUP_DIR}/${BACKUP_FILE}"
```

```bash
#!/bin/bash
# restore.sh

# è®¾ç½®å˜é‡
BACKUP_FILE=$1
BACKUP_DIR="/backup/cost-rag"
RESTORE_DIR="/tmp/cost-rag-restore"

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    exit 1
fi

# åˆ›å»ºä¸´æ—¶ç›®å½•
mkdir -p ${RESTORE_DIR}

# è§£å‹å¤‡ä»½æ–‡ä»¶
tar -xzf ${BACKUP_DIR}/${BACKUP_FILE} -C ${RESTORE_DIR}

# åœæ­¢æœåŠ¡
docker-compose down

# æ¢å¤æ•°æ®åº“
docker-compose up -d postgres
docker-compose exec -T postgres psql -U cost_rag -c "DROP DATABASE IF EXISTS cost_rag;"
docker-compose exec -T postgres psql -U cost_rag -c "CREATE DATABASE cost_rag;"
docker-compose exec -T postgres psql -U cost_rag cost_rag < ${RESTORE_DIR}/postgres_*.sql

# æ¢å¤Redis
docker-compose up -d redis
docker-compose exec -T redis redis-cli FLUSHALL
docker cp ${RESTORE_DIR}/redis_*.rdb cost-rag-redis:/data/dump.rdb
docker-compose restart redis

# æ¢å¤Milvus
docker-compose up -d etcd minio milvus
docker cp ${RESTORE_DIR}/milvus_* cost-rag-milvus:/var/lib/milvus/
docker-compose restart milvus

# æ¢å¤MinIO
docker-compose up -d minio
docker cp ${RESTORE_DIR}/minio_*/data/* cost-rag-minio:/data/

# æ¢å¤Neo4j
docker-compose up -d neo4j
docker cp ${RESTORE_DIR}/neo4j_*/data/* cost-rag-neo4j:/data/

# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm -rf ${RESTORE_DIR}

echo "Restore completed from: ${BACKUP_DIR}/${BACKUP_FILE}"
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### æ„å»ºä¼˜åŒ–

```dockerfile
# å¤šé˜¶æ®µæ„å»ºDockerfile
FROM python:3.11-slim as builder

WORKDIR /app

# å®‰è£…æ„å»ºä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
COPY requirements-prod.txt .

# å®‰è£…ä¾èµ–åˆ°ä¸´æ—¶ç›®å½•
RUN pip install --user --no-cache-dir -r requirements-prod.txt

# ç”Ÿäº§é•œåƒ
FROM python:3.11-slim

WORKDIR /app

# åªå®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y \
    libpq5 \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# ä»builderé˜¶æ®µå¤åˆ¶PythonåŒ…
COPY --from=builder /root/.local /root/.local

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY cost_rag/ ./cost_rag/
COPY scripts/ ./scripts/

# è®¾ç½®PATH
ENV PATH=/root/.local/bin:$PATH

# åˆ›å»ºérootç”¨æˆ·
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["gunicorn", "cost_rag.main:app", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "--bind", "0.0.0.0:8000"]
```

### ç¼“å­˜ä¼˜åŒ–

```yaml
# docker-compose.cache.yml
version: '3.8'

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
      cache_from:
        - cost-rag/api:latest
      target: production
    image: cost-rag/api:${VERSION:-latest}

  # Redisç¼“å­˜é›†ç¾¤
  redis-master:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 1gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_master_data:/data

  redis-slave:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 1gb --maxmemory-policy allkeys-lru --slaveof redis-master 6379
    depends_on:
      - redis-master
    volumes:
      - redis_slave_data:/data

  # ç¼“å­˜ä»£ç†
  redis-proxy:
    image: haproxy:2.8-alpine
    volumes:
      - ./haproxy/redis.cfg:/usr/local/etc/haproxy/haproxy.cfg
    ports:
      - "6380:6380"
    depends_on:
      - redis-master
      - redis-slave

volumes:
  redis_master_data:
  redis_slave_data:
```

### èµ„æºé™åˆ¶ä¼˜åŒ–

```yaml
# docker-compose.resources.yml
version: '3.8'

services:
  api:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
          pids: 100
        reservations:
          cpus: '1.0'
          memory: 1G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
        monitor: 60s
        max_failure_ratio: 0.3

  worker:
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 4G
          pids: 200
        reservations:
          cpus: '2.0'
          memory: 2G

  postgres:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    environment:
      - POSTGRES_SHARED_BUFFERS=1GB
      - POSTGRES_EFFECTIVE_CACHE_SIZE=3GB
      - POSTGRES_WORK_MEM=16MB
      - POSTGRES_MAINTENANCE_WORK_MEM=256MB
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

- **Dockeræ–‡æ¡£**: [Dockerå®˜æ–¹æ–‡æ¡£](https://docs.docker.com/)
- **Docker Composeæ–‡æ¡£**: [Composeå®˜æ–¹æ–‡æ¡£](https://docs.docker.com/compose/)
- **æœ€ä½³å®è·µ**: [Dockeræœ€ä½³å®è·µæŒ‡å—](https://docs.docker.com/develop/dev-best-practices/)
- **æ•…éšœæ’æŸ¥**: [Dockeræ•…éšœæ’æŸ¥æŒ‡å—](https://docs.docker.com/config/troubleshooting/)
- **æŠ€æœ¯æ”¯æŒ**: support@cost-rag.com