# ç¯å¢ƒé…ç½®æŒ‡å—

## ğŸ“‹ ç›®å½•

- [å¼€å‘ç¯å¢ƒé…ç½®](#å¼€å‘ç¯å¢ƒé…ç½®)
- [æµ‹è¯•ç¯å¢ƒé…ç½®](#æµ‹è¯•ç¯å¢ƒé…ç½®)
- [é¢„ç”Ÿäº§ç¯å¢ƒé…ç½®](#é¢„ç”Ÿäº§ç¯å¢ƒé…ç½®)
- [ç”Ÿäº§ç¯å¢ƒé…ç½®](#ç”Ÿäº§ç¯å¢ƒé…ç½®)
- [ç¯å¢ƒå˜é‡ç®¡ç†](#ç¯å¢ƒå˜é‡ç®¡ç†)
- [é…ç½®éªŒè¯](#é…ç½®éªŒè¯)
- [ç¯å¢ƒè¿ç§»](#ç¯å¢ƒè¿ç§»)
- [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)

## ğŸ› ï¸ å¼€å‘ç¯å¢ƒé…ç½®

### 1. ç³»ç»Ÿè¦æ±‚

```yaml
# åŸºç¡€ç¯å¢ƒè¦æ±‚
System:
  OS:
    - Ubuntu 20.04+ / macOS 12+ / Windows 10+
    - Linuxå†…æ ¸ç‰ˆæœ¬ 5.4+
  CPU:
    Minimum: 4æ ¸å¿ƒ
    Recommended: 8æ ¸å¿ƒ+
  Memory:
    Minimum: 8GB RAM
    Recommended: 16GB+ RAM
  Storage:
    Minimum: 50GBå¯ç”¨ç©ºé—´
    Recommended: 100GB+ SSD

# è½¯ä»¶ä¾èµ–
Software:
  Python: 3.11+
  Node.js: 18+
  Docker: 24.0+
  Docker Compose: 2.0+
  Git: 2.30+
  Make: 4.2+

# å¯é€‰å·¥å…·
OptionalTools:
  - PostgreSQL Client: 15+
  - Redis CLI: 7+
  - kubectl: 1.28+
  - Helm: 3.12+
```

### 2. å¿«é€Ÿå¯åŠ¨è„šæœ¬

```bash
#!/bin/bash
# setup-dev.sh - å¼€å‘ç¯å¢ƒå¿«é€Ÿé…ç½®

set -e

echo "ğŸš€ Setting up Cost-RAG development environment..."

# æ£€æŸ¥ç³»ç»Ÿè¦æ±‚
check_requirements() {
    echo "ğŸ“‹ Checking system requirements..."

    # æ£€æŸ¥Python
    if ! command -v python3.11 &> /dev/null; then
        echo "âŒ Python 3.11+ is required"
        exit 1
    fi

    # æ£€æŸ¥Docker
    if ! command -v docker &> /dev/null; then
        echo "âŒ Docker is required"
        exit 1
    fi

    # æ£€æŸ¥Docker Compose
    if ! command -v docker-compose &> /dev/null; then
        echo "âŒ Docker Compose is required"
        exit 1
    fi

    echo "âœ… All requirements satisfied"
}

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
create_venv() {
    echo "ğŸ Creating Python virtual environment..."
    python3.11 -m venv venv
    source venv/bin/activate

    # å‡çº§pip
    pip install --upgrade pip setuptools wheel

    echo "âœ… Virtual environment created"
}

# å®‰è£…Pythonä¾èµ–
install_dependencies() {
    echo "ğŸ“¦ Installing Python dependencies..."

    # å®‰è£…åŸºç¡€ä¾èµ–
    pip install -r requirements.txt

    # å®‰è£…å¼€å‘ä¾èµ–
    pip install -r requirements-dev.txt

    echo "âœ… Dependencies installed"
}

# é…ç½®ç¯å¢ƒå˜é‡
setup_environment() {
    echo "âš™ï¸ Setting up environment configuration..."

    # å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
    if [ ! -f .env ]; then
        cp .env.example .env
        echo "ğŸ“ Please edit .env file with your configuration"
    fi

    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    mkdir -p logs uploads data models config
    chmod 755 logs uploads data models config

    echo "âœ… Environment configured"
}

# å¯åŠ¨åŸºç¡€æœåŠ¡
start_services() {
    echo "ğŸ³ Starting development services..."

    # å¯åŠ¨æ•°æ®åº“å’Œç¼“å­˜æœåŠ¡
    docker-compose -f docker-compose.dev.yml up -d postgres redis

    # ç­‰å¾…æœåŠ¡å°±ç»ª
    echo "â³ Waiting for services to be ready..."
    sleep 10

    # è¿è¡Œæ•°æ®åº“è¿ç§»
    source venv/bin/activate
    alembic upgrade head

    echo "âœ… Services started"
}

# åˆå§‹åŒ–å¼€å‘æ•°æ®
init_dev_data() {
    echo "ğŸ“Š Initializing development data..."

    source venv/bin/activate
    python scripts/init_dev_data.py

    echo "âœ… Development data initialized"
}

# æ‰§è¡Œå®‰è£…æ­¥éª¤
main() {
    check_requirements
    create_venv
    install_dependencies
    setup_environment
    start_services
    init_dev_data

    echo "ğŸ‰ Development environment setup completed!"
    echo ""
    echo "Next steps:"
    echo "1. Activate virtual environment: source venv/bin/activate"
    echo "2. Edit .env file with your configuration"
    echo "3. Start API server: python -m uvicorn cost_rag.main:app --reload"
    echo "4. Start worker: celery -A cost_rag.celery worker --loglevel=info --reload"
    echo ""
    echo "API Documentation: http://localhost:8000/docs"
    echo "Admin Interface: http://localhost:8000/admin"
}

main "$@"
```

### 3. å¼€å‘ç¯å¢ƒDockeré…ç½®

```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  # PostgreSQLå¼€å‘æ•°æ®åº“
  postgres-dev:
    image: postgres:15-alpine
    container_name: cost-rag-postgres-dev
    environment:
      - POSTGRES_DB=cost_rag_dev
      - POSTGRES_USER=dev_user
      - POSTGRES_PASSWORD=dev_password
    volumes:
      - postgres_dev_data:/var/lib/postgresql/data
      - ./scripts/init-db-dev.sql:/docker-entrypoint-initdb.d/init-db.sql
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U dev_user -d cost_rag_dev"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Rediså¼€å‘ç¼“å­˜
  redis-dev:
    image: redis:7-alpine
    container_name: cost-rag-redis-dev
    command: redis-server --appendonly yes
    volumes:
      - redis_dev_data:/data
    ports:
      - "6380:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Milvuså¼€å‘å‘é‡æ•°æ®åº“
  milvus-dev:
    image: milvusdb/milvus:v2.3.0
    container_name: cost-rag-milvus-dev
    command: ["milvus", "run", "standalone"]
    environment:
      ETCD_ENDPOINTS: etcd-dev:2379
      MINIO_ADDRESS: minio-dev:9000
    volumes:
      - milvus_dev_data:/var/lib/milvus
    ports:
      - "19531:19530"
      - "9092:9091"
    depends_on:
      - etcd-dev
      - minio-dev

  # etcd for Milvus
  etcd-dev:
    image: quay.io/coreos/etcd:v3.5.5
    container_name: cost-rag-etcd-dev
    command:
      - etcd
      - --advertise-client-urls=http://127.0.0.1:2379
      - --listen-client-urls=http://0.0.0.0:2379
      - --data-dir=/etcd
    volumes:
      - etcd_dev_data:/etcd

  # MinIOå¼€å‘å­˜å‚¨
  minio-dev:
    image: minio/minio:RELEASE.2023-12-14T18-51-57Z
    container_name: cost-rag-minio-dev
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=devminioadmin
      - MINIO_ROOT_PASSWORD=devminioadmin123
    volumes:
      - minio_dev_data:/data
    ports:
      - "9001:9000"
      - "9002:9001"

  # å¼€å‘å·¥å…·
  adminer:
    image: adminer:latest
    container_name: cost-rag-adminer
    ports:
      - "8080:8080"
    environment:
      - ADMINER_DEFAULT_SERVER=postgres-dev

  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: cost-rag-redis-commander
    ports:
      - "8081:8081"
    environment:
      - REDIS_HOSTS=local:redis-dev:6379
    depends_on:
      - redis-dev

volumes:
  postgres_dev_data:
  redis_dev_data:
  milvus_dev_data:
  etcd_dev_data:
  minio_dev_data:

networks:
  default:
    name: cost-rag-dev-network
```

### 4. å¼€å‘å·¥å…·é…ç½®

```json
// .vscode/settings.json
{
    "python.defaultInterpreterPath": "./venv/bin/python",
    "python.linting.enabled": true,
    "python.linting.pylintEnabled": true,
    "python.linting.flake8Enabled": true,
    "python.linting.mypyEnabled": true,
    "python.formatting.provider": "black",
    "python.formatting.blackArgs": ["--line-length", "88"],
    "python.sortImports.args": ["--profile", "black"],
    "editor.formatOnSave": true,
    "editor.codeActionsOnSave": {
        "source.organizeImports": true
    },
    "files.exclude": {
        "**/__pycache__": true,
        "**/*.pyc": true,
        ".pytest_cache": true,
        ".mypy_cache": true,
        "*.egg-info": true
    },
    "python.testing.pytestEnabled": true,
    "python.testing.pytestArgs": [
        "tests",
        "-v",
        "--cov=cost_rag",
        "--cov-report=html",
        "--cov-report=term-missing"
    ],
    "python.testing.unittestEnabled": false,
    "docker.compose.showQuickStartButton": false,
    "docker.showStartPage": false,
    "files.watcherExclude": {
        "**/__pycache__/**": true,
        "**/*.pyc": true,
        "**/venv/**": true
    }
}
```

```json
// .vscode/launch.json
{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: FastAPI",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "module": "uvicorn",
            "args": [
                "cost_rag.main:app",
                "--host",
                "0.0.0.0",
                "--port",
                "8000",
                "--reload"
            ],
            "console": "integratedTerminal",
            "envFile": "${workspaceFolder}/.env",
            "cwd": "${workspaceFolder}"
        },
        {
            "name": "Python: Celery Worker",
            "type": "python",
            "request": "launch",
            "module": "celery",
            "args": [
                "-A",
                "cost_rag.celery",
                "worker",
                "--loglevel=info",
                "--reload"
            ],
            "console": "integratedTerminal",
            "envFile": "${workspaceFolder}/.env",
            "cwd": "${workspaceFolder}"
        },
        {
            "name": "Python: Run Tests",
            "type": "python",
            "request": "launch",
            "module": "pytest",
            "args": [
                "tests",
                "-v",
                "--cov=cost_rag",
                "--cov-report=html"
            ],
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}"
        }
    ]
}
```

## ğŸ§ª æµ‹è¯•ç¯å¢ƒé…ç½®

### 1. æµ‹è¯•ç¯å¢ƒæ¶æ„

```yaml
# æµ‹è¯•ç¯å¢ƒé…ç½®
TestEnvironment:
  Purpose: è‡ªåŠ¨åŒ–æµ‹è¯•ã€é›†æˆæµ‹è¯•ã€æ€§èƒ½æµ‹è¯•
  Infrastructure:
    - Kubernetesé›†ç¾¤ (3èŠ‚ç‚¹)
    - PostgreSQL (å•å®ä¾‹)
    - Redis (å•å®ä¾‹)
    - Milvus (å•å®ä¾‹)
    - MinIO (å•å®ä¾‹)

  AutoScaling:
    Enabled: false
    FixedInstances: 2

  Monitoring:
    - Basic logging
    - Health checks
    - Test metrics

  Data:
    - æµ‹è¯•æ•°æ®è‡ªåŠ¨ç”Ÿæˆ
    - æ¯æ¬¡æµ‹è¯•åæ¸…ç†
    - éš”ç¦»æµ‹è¯•ç¯å¢ƒ
```

### 2. æµ‹è¯•ç¯å¢ƒéƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# deploy-test.sh

set -e

ENVIRONMENT="test"
NAMESPACE="cost-rag-test"
RELEASE_NAME="cost-rag-test"

echo "ğŸ§ª Deploying Cost-RAG to test environment..."

# åˆ›å»ºæµ‹è¯•å‘½åç©ºé—´
kubectl create namespace ${NAMESPACE} --dry-run=client -o yaml | kubectl apply -f -

# è®¾ç½®æµ‹è¯•æ ‡ç­¾
kubectl label namespace ${NAMESPACE} environment=test --overwrite

# éƒ¨ç½²åº”ç”¨
helm upgrade --install ${RELEASE_NAME} ./helm/cost-rag \
  --namespace ${NAMESPACE} \
  --set environment=test \
  --set api.replicaCount=2 \
  --set worker.replicaCount=2 \
  --set postgresql.primary.persistence.size=100Gi \
  --set redis.master.persistence.size=10Gi \
  --set monitoring.enabled=true \
  --values ./helm/values-test.yaml \
  --wait \
  --timeout 10m

# åˆå§‹åŒ–æµ‹è¯•æ•°æ®
echo "ğŸ“Š Initializing test data..."
kubectl run test-data-init --image=cost-rag/test-data:latest \
  --restart=Never \
  --namespace ${NAMESPACE} \
  --env="DATABASE_URL=postgresql://cost_rag:password@postgresql:5432/cost_rag" \
  --env="REDIS_URL=redis://redis-master:6379/0" \
  --command -- python init_test_data.py

# ç­‰å¾…æ•°æ®åˆå§‹åŒ–å®Œæˆ
kubectl wait --for=condition=complete job/test-data-init --namespace ${NAMESPACE} --timeout=300s

# éªŒè¯éƒ¨ç½²
echo "âœ… Verifying test deployment..."
kubectl get pods -n ${NAMESPACE}
kubectl get services -n ${NAMESPACE}

# è¿è¡Œå¥åº·æ£€æŸ¥
./scripts/health-check.sh --namespace ${NAMESPACE}

echo "ğŸ‰ Test environment deployed successfully!"
echo "Test API URL: https://test-api.cost-rag.com"
```

### 3. æµ‹è¯•é…ç½®æ–‡ä»¶

```yaml
# values-test.yaml
global:
  environment: test
  imageRegistry: "your-registry.com"

api:
  replicaCount: 2
  image:
    tag: "latest"
  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 1Gi
  autoscaling:
    enabled: false

worker:
  replicaCount: 2
  image:
    tag: "latest"
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 1000m
      memory: 2Gi
  autoscaling:
    enabled: false

postgresql:
  auth:
    postgresPassword: "test_password"
    database: "cost_rag_test"
  primary:
    persistence:
      enabled: true
      size: 100Gi
    resources:
      requests:
        cpu: 250m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 1Gi

redis:
  auth:
    enabled: false
  master:
    persistence:
      enabled: true
      size: 10Gi
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 250m
        memory: 256Mi

monitoring:
  enabled: true
  prometheus:
    enabled: true
  grafana:
    enabled: true

ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-test"
  hosts:
    - host: test-api.cost-rag.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: cost-rag-test-tls
      hosts:
        - test-api.cost-rag.com
```

## ğŸ­ é¢„ç”Ÿäº§ç¯å¢ƒé…ç½®

### 1. é¢„ç”Ÿäº§ç¯å¢ƒæ¶æ„

```yaml
# é¢„ç”Ÿäº§ç¯å¢ƒé…ç½®
StagingEnvironment:
  Purpose: ç”Ÿäº§å‰éªŒè¯ã€ç”¨æˆ·éªŒæ”¶æµ‹è¯•
  Infrastructure:
    - Kubernetesé›†ç¾¤ (5èŠ‚ç‚¹)
    - PostgreSQL (ä¸»ä»å¤åˆ¶)
    - Redis (é›†ç¾¤æ¨¡å¼)
    - Milvus (é›†ç¾¤æ¨¡å¼)
    - MinIO (åˆ†å¸ƒå¼)

  AutoScaling:
    Enabled: true
    MinInstances: 2
    MaxInstances: 8

  Monitoring:
    - å®Œæ•´ç›‘æ§æ ˆ
    - æ€§èƒ½åˆ†æ
    - é”™è¯¯è¿½è¸ª

  Data:
    - ç”Ÿäº§æ•°æ®è„±æ•å‰¯æœ¬
    - å®šæœŸåŒæ­¥
    - æ•°æ®éš”ç¦»
```

### 2. é¢„ç”Ÿäº§éƒ¨ç½²é…ç½®

```yaml
# values-staging.yaml
global:
  environment: staging
  imageRegistry: "your-registry.com"

api:
  replicaCount: 3
  image:
    tag: "staging"
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 1000m
      memory: 2Gi
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 8
    targetCPUUtilizationPercentage: 70

worker:
  replicaCount: 5
  image:
    tag: "staging"
  resources:
    requests:
      cpu: 1000m
      memory: 2Gi
    limits:
      cpu: 2000m
      memory: 4Gi
  autoscaling:
    enabled: true
    minReplicas: 3
    maxReplicas: 15
    targetCPUUtilizationPercentage: 70

postgresql:
  auth:
    postgresPassword: "staging_password"
    database: "cost_rag_staging"
  primary:
    persistence:
      enabled: true
      size: 500Gi
    resources:
      requests:
        cpu: 1000m
        memory: 2Gi
      limits:
        cpu: 2000m
        memory: 4Gi
  readReplicas:
    replicaCount: 2
    persistence:
      enabled: true
      size: 500Gi
    resources:
      requests:
        cpu: 500m
        memory: 1Gi
      limits:
        cpu: 1000m
        memory: 2Gi

redis:
  auth:
    enabled: true
    password: "staging_redis_password"
  master:
    persistence:
      enabled: true
      size: 50Gi
    resources:
      requests:
        cpu: 250m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 1Gi
  replica:
    replicaCount: 2
    persistence:
      enabled: true
      size: 50Gi

monitoring:
  enabled: true
  prometheus:
    enabled: true
    retention: 15d
  grafana:
    enabled: true
    persistence:
      enabled: true
      size: 10Gi

ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rate-limit: "500"
  hosts:
    - host: staging-api.cost-rag.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: cost-rag-staging-tls
      hosts:
        - staging-api.cost-rag.com
```

## ğŸš€ ç”Ÿäº§ç¯å¢ƒé…ç½®

### 1. ç”Ÿäº§ç¯å¢ƒæ¶æ„

```yaml
# ç”Ÿäº§ç¯å¢ƒé…ç½®
ProductionEnvironment:
  Purpose: æ­£å¼è¿è¡Œç¯å¢ƒ
  Infrastructure:
    - Kubernetesé›†ç¾¤ (å¤šå¯ç”¨åŒºï¼Œ10+èŠ‚ç‚¹)
    - PostgreSQL (ä¸»ä»å¤åˆ¶ï¼Œè·¨AZ)
    - Redis (é›†ç¾¤æ¨¡å¼ï¼Œè·¨AZ)
    - Milvus (é›†ç¾¤æ¨¡å¼ï¼Œè·¨AZ)
    - MinIO (åˆ†å¸ƒå¼ï¼Œè·¨AZ)
    - CDN (å…¨çƒåˆ†å‘)
    - WAF (å®‰å…¨é˜²æŠ¤)

  HighAvailability:
    - å¤šå¯ç”¨åŒºéƒ¨ç½²
    - è‡ªåŠ¨æ•…éšœè½¬ç§»
    - å¥åº·æ£€æŸ¥
    - è´Ÿè½½å‡è¡¡

  AutoScaling:
    Enabled: true
    MinInstances: 5
    MaxInstances: 50

  Monitoring:
    - å…¨é“¾è·¯ç›‘æ§
    - å®æ—¶å‘Šè­¦
    - æ€§èƒ½åˆ†æ
    - å®¡è®¡æ—¥å¿—

  Security:
    - ç½‘ç»œéš”ç¦»
    - æ•°æ®åŠ å¯†
    - è®¿é—®æ§åˆ¶
    - å®‰å…¨æ‰«æ
```

### 2. ç”Ÿäº§ç¯å¢ƒé…ç½®

```yaml
# values-production.yaml
global:
  environment: production
  imageRegistry: "your-registry.com"

api:
  replicaCount: 5
  image:
    tag: "v1.0.0"
  resources:
    requests:
      cpu: 1000m
      memory: 2Gi
    limits:
      cpu: 2000m
      memory: 4Gi
  autoscaling:
    enabled: true
    minReplicas: 5
    maxReplicas: 50
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - cost-rag-api
          topologyKey: kubernetes.io/hostname

worker:
  replicaCount: 10
  image:
    tag: "v1.0.0"
  resources:
    requests:
      cpu: 2000m
      memory: 4Gi
    limits:
      cpu: 4000m
      memory: 8Gi
  autoscaling:
    enabled: true
    minReplicas: 10
    maxReplicas: 100
    targetCPUUtilizationPercentage: 70

postgresql:
  auth:
    existingSecret: "postgres-secret"
  primary:
    persistence:
      enabled: true
      size: 2000Gi
      storageClass: "io2"
    resources:
      requests:
        cpu: 2000m
        memory: 4Gi
      limits:
        cpu: 4000m
        memory: 8Gi
  readReplicas:
    replicaCount: 3
    persistence:
      enabled: true
      size: 2000Gi
      storageClass: "io2"
    resources:
      requests:
        cpu: 1000m
        memory: 2Gi
      limits:
        cpu: 2000m
        memory: 4Gi

redis:
  auth:
    existingSecret: "redis-secret"
  master:
    persistence:
      enabled: true
      size: 200Gi
      storageClass: "io2"
    resources:
      requests:
        cpu: 500m
        memory: 1Gi
      limits:
        cpu: 1000m
        memory: 2Gi
  replica:
    replicaCount: 3
    persistence:
      enabled: true
      size: 200Gi
      storageClass: "io2"

monitoring:
  enabled: true
  prometheus:
    enabled: true
    retention: 30d
    resources:
      requests:
        cpu: 1000m
        memory: 2Gi
      limits:
        cpu: 2000m
        memory: 4Gi
  grafana:
    enabled: true
    persistence:
      enabled: true
      size: 20Gi
    resources:
      requests:
        cpu: 250m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 1Gi

ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rate-limit: "1000"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
  hosts:
    - host: api.cost-rag.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: cost-rag-production-tls
      hosts:
        - api.cost-rag.com

podDisruptionBudget:
  enabled: true
  api:
    minAvailable: 2
  worker:
    minAvailable: 5

networkPolicy:
  enabled: true
  ingress:
    enabled: true
  egress:
    enabled: true
```

## ğŸ”§ ç¯å¢ƒå˜é‡ç®¡ç†

### 1. ç¯å¢ƒå˜é‡æ¨¡æ¿

```bash
# .env.example
# =============================================================================
# Cost-RAG Environment Variables Template
# Copy this file to .env and update with your values
# =============================================================================

# =============================================================================
# åº”ç”¨åŸºç¡€é…ç½®
# =============================================================================
# åº”ç”¨ç¯å¢ƒ (development, testing, staging, production)
ENVIRONMENT=development

# è°ƒè¯•æ¨¡å¼ (true/false)
DEBUG=true

# æ—¥å¿—çº§åˆ« (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# åº”ç”¨ç‰ˆæœ¬
VERSION=1.0.0

# =============================================================================
# æ•°æ®åº“é…ç½®
# =============================================================================
# PostgreSQLæ•°æ®åº“è¿æ¥
DATABASE_URL=postgresql://cost_rag:password@localhost:5432/cost_rag

# æ•°æ®åº“è¿æ¥æ± é…ç½®
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=30
DATABASE_POOL_TIMEOUT=30
DATABASE_POOL_RECYCLE=3600

# =============================================================================
# Redisç¼“å­˜é…ç½®
# =============================================================================
# Redisè¿æ¥URL
REDIS_URL=redis://localhost:6379/0

# Redisè¿æ¥æ± é…ç½®
REDIS_POOL_SIZE=50
REDIS_POOL_TIMEOUT=10

# =============================================================================
# Milvuså‘é‡æ•°æ®åº“é…ç½®
# =============================================================================
# MilvusæœåŠ¡å™¨åœ°å€
MILVUS_HOST=localhost
MILVUS_PORT=19530

# Milvusè¿æ¥é…ç½®
MILVUS_CONNECTION_TIMEOUT=10
MILVUS_CONNECTION_POOL_SIZE=10

# =============================================================================
# Neo4jå›¾æ•°æ®åº“é…ç½®
# =============================================================================
# Neo4jè¿æ¥URI
NEO4J_URI=bolt://localhost:7687

# Neo4jè®¤è¯
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# =============================================================================
# MinIOå¯¹è±¡å­˜å‚¨é…ç½®
# =============================================================================
# MinIOæœåŠ¡ç«¯ç‚¹
MINIO_ENDPOINT=localhost:9000

# MinIOè®¤è¯
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin123

# å­˜å‚¨æ¡¶é…ç½®
MINIO_BUCKET_NAME=cost-rag-documents
MINIO_SECURE=false

# =============================================================================
# RabbitMQæ¶ˆæ¯é˜Ÿåˆ—é…ç½®
# =============================================================================
# RabbitMQè¿æ¥URL
RABBITMQ_URL=amqp://guest:guest@localhost:5672/

# =============================================================================
# JWTè®¤è¯é…ç½®
# =============================================================================
# JWTå¯†é’¥ (ç”Ÿäº§ç¯å¢ƒè¯·ä½¿ç”¨å¼ºå¯†é’¥)
JWT_SECRET=your-super-secret-jwt-key-here

# JWTç®—æ³•
JWT_ALGORITHM=HS256

# Tokenè¿‡æœŸæ—¶é—´
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# =============================================================================
# OpenAIé…ç½®
# =============================================================================
# OpenAI APIå¯†é’¥
OPENAI_API_KEY=your-openai-api-key-here

# OpenAIæ¨¡å‹é…ç½®
OPENAI_MODEL=gpt-4-turbo
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.1

# =============================================================================
# æ–‡ä»¶å¤„ç†é…ç½®
# =============================================================================
# æ–‡ä»¶ä¸Šä¼ é™åˆ¶
MAX_FILE_SIZE=100MB
ALLOWED_EXTENSIONS=pdf,docx,xlsx,ppt,jpg,png,jpeg

# æ–‡ä»¶å­˜å‚¨è·¯å¾„
UPLOAD_PATH=./uploads
TEMP_PATH=./temp

# =============================================================================
# é‚®ä»¶é…ç½®
# =============================================================================
# SMTPæœåŠ¡å™¨é…ç½®
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password
SMTP_USE_TLS=true

# é‚®ä»¶å‘é€é…ç½®
EMAIL_FROM=noreply@cost-rag.com
EMAIL_FROM_NAME=Cost-RAG System

# =============================================================================
# Celeryé…ç½®
# =============================================================================
# Celeryä»£ç†URL
CELERY_BROKER_URL=amqp://guest:guest@localhost:5672/
CELERY_RESULT_BACKEND=redis://localhost:6379/1

# Celeryä»»åŠ¡é…ç½®
CELERY_TASK_SERIALIZER=json
CELERY_RESULT_SERIALIZER=json
CELERY_ACCEPT_CONTENT=["json"]
CELERY_TIMEZONE=UTC
CELERY_ENABLE_UTC=true

# =============================================================================
# å®‰å…¨é…ç½®
# =============================================================================
# CORSé…ç½®
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8080"]
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=["GET", "POST", "PUT", "DELETE", "OPTIONS"]
CORS_ALLOW_HEADERS=["*"]

# å®‰å…¨å¤´é…ç½®
SECURITY_HEADERS=true
X_FRAME_OPTIONS=DENY
X_CONTENT_TYPE_OPTIONS=nosniff
X_XSS_PROTECTION=1; mode=block

# =============================================================================
# ç›‘æ§é…ç½®
# =============================================================================
# å¥åº·æ£€æŸ¥é…ç½®
HEALTH_CHECK_ENABLED=true
HEALTH_CHECK_PATH=/health

# æŒ‡æ ‡æ”¶é›†é…ç½®
METRICS_ENABLED=true
METRICS_PATH=/metrics

# =============================================================================
# ç¬¬ä¸‰æ–¹æœåŠ¡é…ç½®
# =============================================================================
# Sentryé”™è¯¯è¿½è¸ª
SENTRY_DSN=your-sentry-dsn-here
SENTRY_ENVIRONMENT=development

# New Relicåº”ç”¨ç›‘æ§
NEW_RELIC_LICENSE_KEY=your-newrelic-key-here
NEW_RELIC_APP_NAME=cost-rag

# =============================================================================
# ä¸šåŠ¡é…ç½®
# =============================================================================
# åˆ†é¡µé…ç½®
DEFAULT_PAGE_SIZE=20
MAX_PAGE_SIZE=100

# ç¼“å­˜é…ç½®
CACHE_TTL=3600
CACHE_PREFIX=cost_rag

# APIé™æµé…ç½®
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# =============================================================================
# ç‰¹æ€§å¼€å…³
# =============================================================================
# åŠŸèƒ½å¼€å…³
FEATURE_DOCUMENT_UPLOAD=true
FEATURE_COST_ESTIMATION=true
FEATURE_MULTI_PROJECT_COMPARISON=true
FEATURE_RAG_QUERY=true
FEATURE_KNOWLEDGE_GRAPH=true

# å®éªŒæ€§åŠŸèƒ½
EXPERIMENTAL_FEATURES=false
BETA_FEATURES=true
```

### 2. ç¯å¢ƒå˜é‡éªŒè¯è„šæœ¬

```python
#!/usr/bin/env python3
# validate-env.py - ç¯å¢ƒå˜é‡éªŒè¯è„šæœ¬

import os
import sys
import re
from typing import Dict, List, Any, Optional
from urllib.parse import urlparse


class EnvironmentValidator:
    def __init__(self, env_file: str = ".env"):
        self.env_file = env_file
        self.errors: List[str] = []
        self.warnings: List[str] = []
        self.required_vars = self._get_required_variables()
        self.optional_vars = self._get_optional_variables()

    def _get_required_variables(self) -> Dict[str, Dict[str, Any]]:
        """è·å–å¿…éœ€çš„ç¯å¢ƒå˜é‡é…ç½®"""
        return {
            "DATABASE_URL": {
                "pattern": r"^postgresql://[^:]+:[^@]+@[^:]+:\d+/[^/]+$",
                "description": "PostgreSQLæ•°æ®åº“è¿æ¥URL"
            },
            "REDIS_URL": {
                "pattern": r"^redis://[^:]+:\d+/\d+$",
                "description": "Redisç¼“å­˜è¿æ¥URL"
            },
            "JWT_SECRET": {
                "min_length": 32,
                "description": "JWTå¯†é’¥ï¼Œè‡³å°‘32ä¸ªå­—ç¬¦"
            },
            "OPENAI_API_KEY": {
                "pattern": r"^sk-[a-zA-Z0-9]{48}$",
                "description": "OpenAI APIå¯†é’¥"
            }
        }

    def _get_optional_variables(self) -> Dict[str, Dict[str, Any]]:
        """è·å–å¯é€‰çš„ç¯å¢ƒå˜é‡é…ç½®"""
        return {
            "MILVUS_HOST": {
                "default": "localhost",
                "description": "MilvusæœåŠ¡å™¨åœ°å€"
            },
            "MILVUS_PORT": {
                "default": "19530",
                "type": "int",
                "description": "MilvusæœåŠ¡å™¨ç«¯å£"
            },
            "DEBUG": {
                "default": "false",
                "type": "bool",
                "description": "è°ƒè¯•æ¨¡å¼"
            },
            "LOG_LEVEL": {
                "default": "INFO",
                "choices": ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
                "description": "æ—¥å¿—çº§åˆ«"
            }
        }

    def load_env_file(self) -> Dict[str, str]:
        """åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶"""
        env_vars = {}

        if not os.path.exists(self.env_file):
            self.errors.append(f"ç¯å¢ƒå˜é‡æ–‡ä»¶ {self.env_file} ä¸å­˜åœ¨")
            return env_vars

        try:
            with open(self.env_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()

                    # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
                    if not line or line.startswith('#'):
                        continue

                    # è§£æé”®å€¼å¯¹
                    if '=' in line:
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip()

                        # ç§»é™¤å¼•å·
                        if value.startswith('"') and value.endswith('"'):
                            value = value[1:-1]
                        elif value.startswith("'") and value.endswith("'"):
                            value = value[1:-1]

                        env_vars[key] = value
                    else:
                        self.warnings.append(f"ç¬¬ {line_num} è¡Œæ ¼å¼é”™è¯¯: {line}")

        except Exception as e:
            self.errors.append(f"è¯»å–ç¯å¢ƒå˜é‡æ–‡ä»¶å¤±è´¥: {str(e)}")

        return env_vars

    def validate_variable(self, name: str, value: str, config: Dict[str, Any]) -> bool:
        """éªŒè¯å•ä¸ªç¯å¢ƒå˜é‡"""
        is_valid = True

        # æ£€æŸ¥æœ€å°é•¿åº¦
        if "min_length" in config and len(value) < config["min_length"]:
            self.errors.append(f"{name}: é•¿åº¦ä¸è¶³ï¼Œè‡³å°‘éœ€è¦ {config['min_length']} ä¸ªå­—ç¬¦")
            is_valid = False

        # æ£€æŸ¥æ­£åˆ™è¡¨è¾¾å¼
        if "pattern" in config and not re.match(config["pattern"], value):
            self.errors.append(f"{name}: æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä¸º {config['description']}")
            is_valid = False

        # æ£€æŸ¥ç±»å‹
        if "type" in config:
            if config["type"] == "bool":
                if value.lower() not in ["true", "false"]:
                    self.errors.append(f"{name}: å¿…é¡»ä¸º true æˆ– false")
                    is_valid = False
            elif config["type"] == "int":
                if not value.isdigit():
                    self.errors.append(f"{name}: å¿…é¡»ä¸ºæ•´æ•°")
                    is_valid = False

        # æ£€æŸ¥é€‰æ‹©é¡¹
        if "choices" in config and value not in config["choices"]:
            self.errors.append(f"{name}: å¿…é¡»ä¸ºä»¥ä¸‹å€¼ä¹‹ä¸€: {', '.join(config['choices'])}")
            is_valid = False

        return is_valid

    def validate_database_url(self, url: str) -> bool:
        """éªŒè¯æ•°æ®åº“URL"""
        try:
            parsed = urlparse(url)

            if parsed.scheme != "postgresql":
                self.errors.append("DATABASE_URL: å¿…é¡»ä½¿ç”¨ PostgreSQL åè®®")
                return False

            if not all([parsed.hostname, parsed.username, parsed.password]):
                self.errors.append("DATABASE_URL: ç¼ºå°‘å¿…è¦çš„ä¸»æœºã€ç”¨æˆ·åæˆ–å¯†ç ")
                return False

            if not parsed.path or parsed.path == "/":
                self.errors.append("DATABASE_URL: ç¼ºå°‘æ•°æ®åº“åç§°")
                return False

            return True

        except Exception:
            self.errors.append("DATABASE_URL: URLæ ¼å¼æ— æ•ˆ")
            return False

    def validate_redis_url(self, url: str) -> bool:
        """éªŒè¯Redis URL"""
        try:
            parsed = urlparse(url)

            if parsed.scheme != "redis":
                self.errors.append("REDIS_URL: å¿…é¡»ä½¿ç”¨ Redis åè®®")
                return False

            if not parsed.hostname:
                self.errors.append("REDIS_URL: ç¼ºå°‘ä¸»æœºåœ°å€")
                return False

            if not parsed.path or parsed.path == "/":
                self.errors.append("REDIS_URL: ç¼ºå°‘æ•°æ®åº“ç¼–å·")
                return False

            db_num = parsed.path.lstrip("/")
            if not db_num.isdigit():
                self.errors.append("REDIS_URL: æ•°æ®åº“ç¼–å·å¿…é¡»ä¸ºæ•´æ•°")
                return False

            return True

        except Exception:
            self.errors.append("REDIS_URL: URLæ ¼å¼æ— æ•ˆ")
            return False

    def validate_security(self, env_vars: Dict[str, str]) -> None:
        """éªŒè¯å®‰å…¨ç›¸å…³é…ç½®"""
        # æ£€æŸ¥ç”Ÿäº§ç¯å¢ƒé…ç½®
        if env_vars.get("ENVIRONMENT") == "production":
            if env_vars.get("DEBUG", "false").lower() == "true":
                self.warnings.append("ç”Ÿäº§ç¯å¢ƒä¸åº”å¯ç”¨è°ƒè¯•æ¨¡å¼")

            if env_vars.get("JWT_SECRET") == "your-super-secret-jwt-key-here":
                self.errors.append("ç”Ÿäº§ç¯å¢ƒå¿…é¡»è®¾ç½®å®‰å…¨çš„JWTå¯†é’¥")

            if env_vars.get("DATABASE_URL", "").contains("localhost"):
                self.warnings.append("ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ä¸“ç”¨æ•°æ®åº“æœåŠ¡å™¨")

    def validate(self) -> bool:
        """æ‰§è¡ŒéªŒè¯"""
        print(f"ğŸ” éªŒè¯ç¯å¢ƒå˜é‡æ–‡ä»¶: {self.env_file}")
        print("-" * 50)

        env_vars = self.load_env_file()

        if self.errors:
            print("âŒ ç¯å¢ƒå˜é‡æ–‡ä»¶åŠ è½½å¤±è´¥:")
            for error in self.errors:
                print(f"   â€¢ {error}")
            return False

        # éªŒè¯å¿…éœ€å˜é‡
        missing_vars = []
        for var_name, config in self.required_vars.items():
            if var_name not in env_vars:
                missing_vars.append(var_name)
            else:
                self.validate_variable(var_name, env_vars[var_name], config)

        if missing_vars:
            self.errors.insert(0, f"ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")

        # éªŒè¯ç‰¹å®šå˜é‡
        if "DATABASE_URL" in env_vars:
            self.validate_database_url(env_vars["DATABASE_URL"])

        if "REDIS_URL" in env_vars:
            self.validate_redis_url(env_vars["REDIS_URL"])

        # éªŒè¯å®‰å…¨é…ç½®
        self.validate_security(env_vars)

        # è®¾ç½®é»˜è®¤å€¼
        for var_name, config in self.optional_vars.items():
            if var_name not in env_vars and "default" in config:
                env_vars[var_name] = config["default"]
                print(f"ğŸ“ ä½¿ç”¨é»˜è®¤å€¼: {var_name}={config['default']}")

        # è¾“å‡ºç»“æœ
        print("\nğŸ“Š éªŒè¯ç»“æœ:")
        print("-" * 30)

        if self.errors:
            print("âŒ é”™è¯¯:")
            for error in self.errors:
                print(f"   â€¢ {error}")

        if self.warnings:
            print("âš ï¸  è­¦å‘Š:")
            for warning in self.warnings:
                print(f"   â€¢ {warning}")

        if not self.errors and not self.warnings:
            print("âœ… æ‰€æœ‰ç¯å¢ƒå˜é‡é…ç½®æ­£ç¡®!")

        return len(self.errors) == 0

    def generate_example(self) -> None:
        """ç”Ÿæˆç¤ºä¾‹é…ç½®æ–‡ä»¶"""
        example_file = f"{self.env_file}.example"

        with open(example_file, 'w', encoding='utf-8') as f:
            f.write("# Cost-RAG Environment Variables Example\n")
            f.write("# Copy this file to .env and update with your values\n\n")

            f.write("# Required Variables\n")
            for var_name, config in self.required_vars.items():
                f.write(f"# {config['description']}\n")
                f.write(f"{var_name}=\n\n")

            f.write("# Optional Variables\n")
            for var_name, config in self.optional_vars.items():
                f.write(f"# {config['description']}")
                if "default" in config:
                    f.write(f" (é»˜è®¤: {config['default']})")
                f.write("\n")
                f.write(f"# {var_name}={config.get('default', '')}\n\n")

        print(f"ğŸ“ ç¤ºä¾‹é…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {example_file}")


def main():
    import argparse

    parser = argparse.ArgumentParser(description="éªŒè¯ç¯å¢ƒå˜é‡é…ç½®")
    parser.add_argument("--env-file", default=".env", help="ç¯å¢ƒå˜é‡æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--generate-example", action="store_true", help="ç”Ÿæˆç¤ºä¾‹é…ç½®æ–‡ä»¶")

    args = parser.parse_args()

    validator = EnvironmentValidator(args.env_file)

    if args.generate_example:
        validator.generate_example()
        return

    is_valid = validator.validate()

    sys.exit(0 if is_valid else 1)


if __name__ == "__main__":
    main()
```

## âœ… é…ç½®éªŒè¯

### 1. å¥åº·æ£€æŸ¥è„šæœ¬

```bash
#!/bin/bash
# health-check.sh

set -e

NAMESPACE="default"
TIMEOUT=300
VERBOSE=false

# è§£æå‘½ä»¤è¡Œå‚æ•°
while [[ $# -gt 0 ]]; do
    case $1 in
        --namespace)
            NAMESPACE="$2"
            shift 2
            ;;
        --timeout)
            TIMEOUT="$2"
            shift 2
            ;;
        --verbose|-v)
            VERBOSE=true
            shift
            ;;
        *)
            echo "æœªçŸ¥å‚æ•°: $1"
            exit 1
            ;;
    esac
done

echo "ğŸ” æ‰§è¡Œå¥åº·æ£€æŸ¥..."
echo "å‘½åç©ºé—´: $NAMESPACE"
echo "è¶…æ—¶æ—¶é—´: ${TIMEOUT}ç§’"
echo "---"

# æ£€æŸ¥PodçŠ¶æ€
check_pods() {
    echo "ğŸ“¦ æ£€æŸ¥PodçŠ¶æ€..."

    local pod_status=$(kubectl get pods -n $NAMESPACE --no-headers 2>/dev/null)

    if [ -z "$pod_status" ]; then
        echo "âŒ æ— æ³•è·å–PodçŠ¶æ€"
        return 1
    fi

    echo "$pod_status" | while read -r line; do
        local pod_name=$(echo $line | awk '{print $1}')
        local pod_ready=$(echo $line | awk '{print $2}')
        local pod_status=$(echo $line | awk '{print $3}')
        local pod_restarts=$(echo $line | awk '{print $4}')

        if [ "$VERBOSE" = true ]; then
            echo "   Pod: $pod_name | Ready: $pod_ready | Status: $pod_status | Restarts: $pod_restarts"
        fi

        # æ£€æŸ¥Podæ˜¯å¦å°±ç»ª
        local ready_expected=$(echo $pod_ready | cut -d'/' -f2)
        local ready_actual=$(echo $pod_ready | cut -d'/' -f1)

        if [ "$ready_actual" -lt "$ready_expected" ]; then
            echo "âš ï¸  Pod $pod_name æœªå®Œå…¨å°±ç»ª ($pod_ready)"
        elif [ "$pod_status" != "Running" ] && [ "$pod_status" != "Completed" ]; then
            echo "âŒ Pod $pod_name çŠ¶æ€å¼‚å¸¸: $pod_status"
        fi
    done

    echo "âœ… PodçŠ¶æ€æ£€æŸ¥å®Œæˆ"
}

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
check_services() {
    echo "ğŸ”— æ£€æŸ¥æœåŠ¡çŠ¶æ€..."

    local services=$(kubectl get services -n $NAMESPACE --no-headers 2>/dev/null)

    if [ -z "$services" ]; then
        echo "âŒ æ— æ³•è·å–æœåŠ¡çŠ¶æ€"
        return 1
    fi

    echo "$services" | while read -r line; do
        local service_name=$(echo $line | awk '{print $1}')
        local service_type=$(echo $line | awk '{print $2}')
        local cluster_ip=$(echo $line | awk '{print $3}')
        local ports=$(echo $line | awk '{print $5}')

        if [ "$VERBOSE" = true ]; then
            echo "   Service: $service_name | Type: $service_type | IP: $cluster_ip | Ports: $ports"
        fi

        # æ£€æŸ¥ClusterIP
        if [ "$service_type" = "ClusterIP" ] && [ "$cluster_ip" = "<none>" ]; then
            echo "âš ï¸  Service $service_name æ²¡æœ‰åˆ†é…ClusterIP"
        fi
    done

    echo "âœ… æœåŠ¡çŠ¶æ€æ£€æŸ¥å®Œæˆ"
}

# æ£€æŸ¥IngressçŠ¶æ€
check_ingress() {
    echo "ğŸŒ æ£€æŸ¥IngressçŠ¶æ€..."

    local ingress_list=$(kubectl get ingress -n $NAMESPACE --no-headers 2>/dev/null)

    if [ -z "$ingress_list" ]; then
        echo "â„¹ï¸  æ²¡æœ‰æ‰¾åˆ°Ingressèµ„æº"
        return 0
    fi

    echo "$ingress_list" | while read -r line; do
        local ingress_name=$(echo $line | awk '{print $1}')
        local ingress_class=$(echo $line | awk '{print $2}')
        local hosts=$(echo $line | awk '{print $3}')
        local address=$(echo $line | awk '{print $4}')
        local ports=$(echo $line | awk '{print $5}')

        if [ "$VERBOSE" = true ]; then
            echo "   Ingress: $ingress_name | Class: $ingress_class | Hosts: $hosts | Address: $address"
        fi

        # æ£€æŸ¥åœ°å€åˆ†é…
        if [ "$address" = "<pending>" ]; then
            echo "âš ï¸  Ingress $ingress_name åœ°å€åˆ†é…ä¸­..."
        elif [ -z "$address" ] || [ "$address" = "<none>" ]; then
            echo "âŒ Ingress $ingress_name æ²¡æœ‰åˆ†é…åœ°å€"
        fi
    done

    echo "âœ… IngressçŠ¶æ€æ£€æŸ¥å®Œæˆ"
}

# æ£€æŸ¥APIå¥åº·çŠ¶æ€
check_api_health() {
    echo "ğŸ¥ æ£€æŸ¥APIå¥åº·çŠ¶æ€..."

    local api_url="http://api.cost-rag.com/health"

    # å¦‚æœæ˜¯æœ¬åœ°å¼€å‘ï¼Œä½¿ç”¨localhost
    if [ "$NAMESPACE" = "default" ]; then
        api_url="http://localhost:8000/health"
    fi

    # ç­‰å¾…æœåŠ¡å“åº”
    local end_time=$(($(date +%s) + TIMEOUT))

    while [ $(date +%s) -lt $end_time ]; do
        if curl -s -f "$api_url" > /dev/null 2>&1; then
            echo "âœ… APIå¥åº·æ£€æŸ¥é€šè¿‡"
            return 0
        fi

        if [ "$VERBOSE" = true ]; then
            echo "   ç­‰å¾…APIå“åº”... ($(date))"
        fi

        sleep 5
    done

    echo "âŒ APIå¥åº·æ£€æŸ¥å¤±è´¥"
    return 1
}

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
check_database_connection() {
    echo "ğŸ—„ï¸  æ£€æŸ¥æ•°æ®åº“è¿æ¥..."

    local db_host="cost-rag-postgres"
    local db_port="5432"

    # ç­‰å¾…æ•°æ®åº“å°±ç»ª
    local end_time=$(($(date +%s) + TIMEOUT))

    while [ $(date +%s) -lt $end_time ]; do
        if kubectl exec -n $NAMESPACE deployment/cost-rag-api -- pg_isready -h $db_host -p $db_port > /dev/null 2>&1; then
            echo "âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸"
            return 0
        fi

        if [ "$VERBOSE" = true ]; then
            echo "   ç­‰å¾…æ•°æ®åº“è¿æ¥... ($(date))"
        fi

        sleep 5
    done

    echo "âŒ æ•°æ®åº“è¿æ¥å¤±è´¥"
    return 1
}

# æ£€æŸ¥Redisè¿æ¥
check_redis_connection() {
    echo "ğŸ“¦ æ£€æŸ¥Redisè¿æ¥..."

    local redis_host="cost-rag-redis-master"
    local redis_port="6379"

    # ç­‰å¾…Rediså°±ç»ª
    local end_time=$(($(date +%s) + TIMEOUT))

    while [ $(date +%s) -lt $end_time ]; do
        if kubectl exec -n $NAMESPACE deployment/cost-rag-api -- redis-cli -h $redis_host -p $redis_port ping > /dev/null 2>&1; then
            echo "âœ… Redisè¿æ¥æ­£å¸¸"
            return 0
        fi

        if [ "$VERBOSE" = true ]; then
            echo "   ç­‰å¾…Redisè¿æ¥... ($(date))"
        fi

        sleep 5
    done

    echo "âŒ Redisè¿æ¥å¤±è´¥"
    return 1
}

# æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ
check_resource_usage() {
    echo "ğŸ“Š æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ..."

    # æ£€æŸ¥CPUå’Œå†…å­˜ä½¿ç”¨
    kubectl top pods -n $NAMESPACE --no-headers 2>/dev/null | while read -r line; do
        local pod_name=$(echo $line | awk '{print $1}')
        local cpu_usage=$(echo $line | awk '{print $2}')
        local memory_usage=$(echo $line | awk '{print $3}')

        if [ "$VERBOSE" = true ]; then
            echo "   $pod_name: CPU=$cpu_usage, Memory=$memory_usage"
        fi

        # æ£€æŸ¥CPUä½¿ç”¨ç‡
        local cpu_value=$(echo $cpu_usage | sed 's/m//')
        if [ "$cpu_value" -gt 1000 ]; then
            echo "âš ï¸  Pod $pod_name CPUä½¿ç”¨ç‡è¾ƒé«˜: $cpu_usage"
        fi

        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        local memory_value=$(echo $memory_usage | sed 's/Mi//')
        if [ "$memory_value" -gt 2000 ]; then
            echo "âš ï¸  Pod $pod_name å†…å­˜ä½¿ç”¨è¾ƒé«˜: $memory_usage"
        fi
    done

    echo "âœ… èµ„æºä½¿ç”¨æƒ…å†µæ£€æŸ¥å®Œæˆ"
}

# ä¸»æ£€æŸ¥å‡½æ•°
main() {
    local start_time=$(date +%s)
    local checks_passed=0
    local total_checks=6

    # æ‰§è¡Œå„é¡¹æ£€æŸ¥
    if check_pods; then ((checks_passed++)); fi
    if check_services; then ((checks_passed++)); fi
    if check_ingress; then ((checks_passed++)); fi
    if check_api_health; then ((checks_passed++)); fi
    if check_database_connection; then ((checks_passed++)); fi
    if check_redis_connection; then ((checks_passed++)); fi

    # æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µï¼ˆå¯é€‰ï¼‰
    if [ "$VERBOSE" = true ]; then
        check_resource_usage
    fi

    local end_time=$(date +%s)
    local duration=$((end_time - start_time))

    echo "---"
    echo "ğŸ“ˆ å¥åº·æ£€æŸ¥å®Œæˆ!"
    echo "é€šè¿‡æ£€æŸ¥: $checks_passed/$total_checks"
    echo "ç”¨æ—¶: ${duration}ç§’"

    if [ $checks_passed -eq $total_checks ]; then
        echo "ğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡!"
        exit 0
    else
        echo "âŒ éƒ¨åˆ†æ£€æŸ¥å¤±è´¥ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯"
        exit 1
    fi
}

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    cat << EOF
Cost-RAG å¥åº·æ£€æŸ¥å·¥å…·

ç”¨æ³•: $0 [é€‰é¡¹]

é€‰é¡¹:
  --namespace <name>    æŒ‡å®šå‘½åç©ºé—´ (é»˜è®¤: default)
  --timeout <seconds>   è®¾ç½®è¶…æ—¶æ—¶é—´ (é»˜è®¤: 300)
  --verbose, -v         æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
  --help, -h           æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

ç¤ºä¾‹:
  $0                           # ä½¿ç”¨é»˜è®¤é…ç½®
  $0 --namespace production    # æ£€æŸ¥ç”Ÿäº§ç¯å¢ƒ
  $0 --verbose                 # æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
  $0 --timeout 600             # è®¾ç½®10åˆ†é’Ÿè¶…æ—¶

EOF
}

# æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
if [[ "$1" == "--help" || "$1" == "-h" ]]; then
    show_help
    exit 0
fi

# æ£€æŸ¥kubectlæ˜¯å¦å¯ç”¨
if ! command -v kubectl &> /dev/null; then
    echo "âŒ kubectl å‘½ä»¤æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿å·²å®‰è£…å¹¶é…ç½®"
    exit 1
fi

# æ£€æŸ¥æ˜¯å¦è¿æ¥åˆ°é›†ç¾¤
if ! kubectl cluster-info &> /dev/null; then
    echo "âŒ æ— æ³•è¿æ¥åˆ°Kubernetesé›†ç¾¤"
    exit 1
fi

# æ‰§è¡Œä¸»æ£€æŸ¥
main
```

## ğŸ”„ ç¯å¢ƒè¿ç§»

### 1. æ•°æ®è¿ç§»è„šæœ¬

```python
#!/usr/bin/env python3
# migrate-environment.py - ç¯å¢ƒæ•°æ®è¿ç§»å·¥å…·

import os
import sys
import argparse
import logging
from typing import Dict, List, Optional
from datetime import datetime
import psycopg2
import redis
from minio import Minio
from minio.error import S3Error
import json


class EnvironmentMigrator:
    def __init__(self, source_config: Dict, target_config: Dict):
        self.source_config = source_config
        self.target_config = target_config
        self.logger = self._setup_logger()

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger("environment_migrator")
        logger.setLevel(logging.INFO)

        # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)

        # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
        os.makedirs("logs", exist_ok=True)
        file_handler = logging.FileHandler(f"logs/migration_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
        file_handler.setLevel(logging.DEBUG)

        # è®¾ç½®æ ¼å¼
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        file_handler.setFormatter(formatter)

        logger.addHandler(console_handler)
        logger.addHandler(file_handler)

        return logger

    def migrate_database(self, tables: Optional[List[str]] = None) -> bool:
        """è¿ç§»æ•°æ®åº“æ•°æ®"""
        self.logger.info("å¼€å§‹æ•°æ®åº“è¿ç§»...")

        try:
            # è¿æ¥æºæ•°æ®åº“
            source_conn = psycopg2.connect(
                host=self.source_config['db_host'],
                port=self.source_config['db_port'],
                database=self.source_config['db_name'],
                user=self.source_config['db_user'],
                password=self.source_config['db_password']
            )

            # è¿æ¥ç›®æ ‡æ•°æ®åº“
            target_conn = psycopg2.connect(
                host=self.target_config['db_host'],
                port=self.target_config['db_port'],
                database=self.target_config['db_name'],
                user=self.target_config['db_user'],
                password=self.target_config['db_password']
            )

            source_cursor = source_conn.cursor()
            target_cursor = target_conn.cursor()

            # è·å–è¡¨åˆ—è¡¨
            if not tables:
                source_cursor.execute("""
                    SELECT table_name
                    FROM information_schema.tables
                    WHERE table_schema = 'public'
                    AND table_type = 'BASE TABLE'
                    ORDER BY table_name
                """)
                tables = [row[0] for row in source_cursor.fetchall()]

            total_tables = len(tables)
            migrated_tables = 0

            for table_name in tables:
                self.logger.info(f"è¿ç§»è¡¨: {table_name}")

                try:
                    # è·å–è¡¨æ•°æ®
                    source_cursor.execute(f"SELECT * FROM {table_name}")
                    columns = [desc[0] for desc in source_cursor.description]
                    rows = source_cursor.fetchall()

                    if not rows:
                        self.logger.info(f"è¡¨ {table_name} ä¸ºç©ºï¼Œè·³è¿‡")
                        continue

                    # æ¸…ç©ºç›®æ ‡è¡¨
                    target_cursor.execute(f"TRUNCATE TABLE {table_name} RESTART IDENTITY CASCADE")

                    # æ‰¹é‡æ’å…¥æ•°æ®
                    batch_size = 1000
                    for i in range(0, len(rows), batch_size):
                        batch = rows[i:i + batch_size]

                        # æ„å»ºæ’å…¥è¯­å¥
                        placeholders = ', '.join(['%s'] * len(columns))
                        insert_query = f"""
                            INSERT INTO {table_name} ({', '.join(columns)})
                            VALUES ({placeholders})
                        """

                        target_cursor.executemany(insert_query, batch)
                        target_conn.commit()

                    migrated_tables += 1
                    self.logger.info(f"è¡¨ {table_name} è¿ç§»å®Œæˆï¼Œå…± {len(rows)} æ¡è®°å½•")

                except Exception as e:
                    self.logger.error(f"è¿ç§»è¡¨ {table_name} å¤±è´¥: {str(e)}")
                    target_conn.rollback()
                    continue

            # å…³é—­è¿æ¥
            source_cursor.close()
            target_cursor.close()
            source_conn.close()
            target_conn.close()

            self.logger.info(f"æ•°æ®åº“è¿ç§»å®Œæˆ: {migrated_tables}/{total_tables} ä¸ªè¡¨")
            return migrated_tables == total_tables

        except Exception as e:
            self.logger.error(f"æ•°æ®åº“è¿ç§»å¤±è´¥: {str(e)}")
            return False

    def migrate_redis_data(self) -> bool:
        """è¿ç§»Redisæ•°æ®"""
        self.logger.info("å¼€å§‹Redisæ•°æ®è¿ç§»...")

        try:
            # è¿æ¥æºRedis
            source_redis = redis.Redis(
                host=self.source_config['redis_host'],
                port=self.source_config['redis_port'],
                db=self.source_config['redis_db'],
                decode_responses=True
            )

            # è¿æ¥ç›®æ ‡Redis
            target_redis = redis.Redis(
                host=self.target_config['redis_host'],
                port=self.target_config['redis_port'],
                db=self.target_config['redis_db'],
                decode_responses=True
            )

            # è·å–æ‰€æœ‰é”®
            keys = source_redis.keys('*')
            total_keys = len(keys)
            migrated_keys = 0

            for key in keys:
                try:
                    # è·å–é”®ç±»å‹
                    key_type = source_redis.type(key)

                    if key_type == 'string':
                        value = source_redis.get(key)
                        target_redis.set(key, value)
                    elif key_type == 'hash':
                        value = source_redis.hgetall(key)
                        target_redis.hmset(key, value)
                    elif key_type == 'list':
                        value = source_redis.lrange(key, 0, -1)
                        target_redis.delete(key)
                        for item in value:
                            target_redis.rpush(key, item)
                    elif key_type == 'set':
                        value = source_redis.smembers(key)
                        target_redis.sadd(key, *value)
                    elif key_type == 'zset':
                        value = source_redis.zrange(key, 0, -1, withscores=True)
                        for member, score in value:
                            target_redis.zadd(key, {member: score})

                    migrated_keys += 1

                    if migrated_keys % 1000 == 0:
                        self.logger.info(f"å·²è¿ç§» {migrated_keys}/{total_keys} ä¸ªé”®")

                except Exception as e:
                    self.logger.error(f"è¿ç§»é”® {key} å¤±è´¥: {str(e)}")
                    continue

            self.logger.info(f"Redisæ•°æ®è¿ç§»å®Œæˆ: {migrated_keys}/{total_keys} ä¸ªé”®")
            return migrated_keys == total_keys

        except Exception as e:
            self.logger.error(f"Redisæ•°æ®è¿ç§»å¤±è´¥: {str(e)}")
            return False

    def migrate_minio_data(self, bucket_name: str) -> bool:
        """è¿ç§»MinIOå¯¹è±¡å­˜å‚¨æ•°æ®"""
        self.logger.info(f"å¼€å§‹è¿ç§»MinIOå­˜å‚¨æ¡¶: {bucket_name}")

        try:
            # è¿æ¥æºMinIO
            source_client = Minio(
                self.source_config['minio_endpoint'],
                access_key=self.source_config['minio_access_key'],
                secret_key=self.source_config['minio_secret_key'],
                secure=self.source_config.get('minio_secure', False)
            )

            # è¿æ¥ç›®æ ‡MinIO
            target_client = Minio(
                self.target_config['minio_endpoint'],
                access_key=self.target_config['minio_access_key'],
                secret_key=self.target_config['minio_secret_key'],
                secure=self.target_config.get('minio_secure', False)
            )

            # åˆ›å»ºç›®æ ‡å­˜å‚¨æ¡¶
            if not target_client.bucket_exists(bucket_name):
                target_client.make_bucket(bucket_name)

            # è·å–å¯¹è±¡åˆ—è¡¨
            objects = source_client.list_objects(bucket_name, recursive=True)
            total_objects = 0
            migrated_objects = 0

            # å…ˆè®¡ç®—æ€»æ•°
            source_client = Minio(
                self.source_config['minio_endpoint'],
                access_key=self.source_config['minio_access_key'],
                secret_key=self.source_config['minio_secret_key'],
                secure=self.source_config.get('minio_secure', False)
            )
            for _ in source_client.list_objects(bucket_name, recursive=True):
                total_objects += 1

            # è¿ç§»å¯¹è±¡
            for obj in source_client.list_objects(bucket_name, recursive=True):
                try:
                    # è·å–å¯¹è±¡æ•°æ®
                    response = source_client.get_object(bucket_name, obj.object_name)
                    data = response.read()

                    # ä¸Šä¼ åˆ°ç›®æ ‡å­˜å‚¨æ¡¶
                    target_client.put_object(
                        bucket_name,
                        obj.object_name,
                        data=data,
                        length=len(data),
                        content_type=response.headers.get('content-type')
                    )

                    migrated_objects += 1

                    if migrated_objects % 100 == 0:
                        self.logger.info(f"å·²è¿ç§» {migrated_objects}/{total_objects} ä¸ªå¯¹è±¡")

                except Exception as e:
                    self.logger.error(f"è¿ç§»å¯¹è±¡ {obj.object_name} å¤±è´¥: {str(e)}")
                    continue

            self.logger.info(f"MinIOæ•°æ®è¿ç§»å®Œæˆ: {migrated_objects}/{total_objects} ä¸ªå¯¹è±¡")
            return migrated_objects == total_objects

        except Exception as e:
            self.logger.error(f"MinIOæ•°æ®è¿ç§»å¤±è´¥: {str(e)}")
            return False

    def generate_migration_report(self, results: Dict[str, bool]) -> None:
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
        report = {
            "migration_time": datetime.now().isoformat(),
            "source_environment": self.source_config.get('environment', 'unknown'),
            "target_environment": self.target_config.get('environment', 'unknown'),
            "results": results,
            "summary": {
                "total_components": len(results),
                "successful_migrations": sum(results.values()),
                "failed_migrations": len(results) - sum(results.values())
            }
        }

        # ä¿å­˜æŠ¥å‘Š
        report_file = f"migration_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        self.logger.info(f"è¿ç§»æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

        # æ‰“å°æ‘˜è¦
        print("\n" + "="*50)
        print("è¿ç§»æ‘˜è¦")
        print("="*50)
        print(f"æºç¯å¢ƒ: {report['source_environment']}")
        print(f"ç›®æ ‡ç¯å¢ƒ: {report['target_environment']}")
        print(f"è¿ç§»æ—¶é—´: {report['migration_time']}")
        print(f"æ€»ç»„ä»¶æ•°: {report['summary']['total_components']}")
        print(f"æˆåŠŸè¿ç§»: {report['summary']['successful_migrations']}")
        print(f"å¤±è´¥è¿ç§»: {report['summary']['failed_migrations']}")
        print("="*50)

    def execute_migration(self, components: List[str]) -> bool:
        """æ‰§è¡Œå®Œæ•´è¿ç§»"""
        self.logger.info("å¼€å§‹ç¯å¢ƒè¿ç§»...")

        results = {}

        if 'database' in components:
            results['database'] = self.migrate_database()

        if 'redis' in components:
            results['redis'] = self.migrate_redis_data()

        if 'minio' in components:
            results['minio'] = self.migrate_minio_data('cost-rag-documents')

        # ç”ŸæˆæŠ¥å‘Š
        self.generate_migration_report(results)

        # è¿”å›æ•´ä½“ç»“æœ
        return all(results.values())


def load_config(config_file: str) -> Dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_file, 'r', encoding='utf-8') as f:
        return json.load(f)


def main():
    parser = argparse.ArgumentParser(description="ç¯å¢ƒæ•°æ®è¿ç§»å·¥å…·")
    parser.add_argument("--source-config", required=True, help="æºç¯å¢ƒé…ç½®æ–‡ä»¶")
    parser.add_argument("--target-config", required=True, help="ç›®æ ‡ç¯å¢ƒé…ç½®æ–‡ä»¶")
    parser.add_argument("--components", nargs='+',
                       choices=['database', 'redis', 'minio'],
                       default=['database', 'redis', 'minio'],
                       help="è¦è¿ç§»çš„ç»„ä»¶")
    parser.add_argument("--dry-run", action="store_true", help="åªæ˜¾ç¤ºå°†è¦è¿ç§»çš„å†…å®¹ï¼Œä¸æ‰§è¡Œå®é™…è¿ç§»")

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    try:
        source_config = load_config(args.source_config)
        target_config = load_config(args.target_config)
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
        sys.exit(1)

    # åˆ›å»ºè¿ç§»å™¨
    migrator = EnvironmentMigrator(source_config, target_config)

    if args.dry_run:
        print("ğŸ” é¢„æ¼”æ¨¡å¼ - ä¸ä¼šæ‰§è¡Œå®é™…è¿ç§»")
        print(f"æºç¯å¢ƒ: {source_config.get('environment', 'unknown')}")
        print(f"ç›®æ ‡ç¯å¢ƒ: {target_config.get('environment', 'unknown')}")
        print(f"è¿ç§»ç»„ä»¶: {', '.join(args.components)}")
        return

    # æ‰§è¡Œè¿ç§»
    success = migrator.execute_migration(args.components)

    if success:
        print("ğŸ‰ ç¯å¢ƒè¿ç§»æˆåŠŸå®Œæˆ!")
        sys.exit(0)
    else:
        print("âŒ ç¯å¢ƒè¿ç§»å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—")
        sys.exit(1)


if __name__ == "__main__":
    main()
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

- **ç¯å¢ƒé…ç½®**: [é…ç½®æ¨¡æ¿æ–‡ä»¶](../config/)
- **éƒ¨ç½²è„šæœ¬**: [scriptsç›®å½•](../scripts/)
- **æ•…éšœæ’æŸ¥**: [æ•…éšœæ’æŸ¥æŒ‡å—](../troubleshooting/)
- **æŠ€æœ¯æ”¯æŒ**: support@cost-rag.com